//---------------------------------------------------------------------------

#pragma hdrstop

#include "Network.h"
//---------------------------------------------------------------------------
#pragma package(smart_init)
//---------------------------------------------------------------------------

Network::Network(int n0, int n1, int n2) {
	SetTheNumberOfNeuronsForEachLayer(n0, n1, n2);
	GenerateWeights();
}
//---------------------------------------------------------------------------

void Network::SetTheNumberOfNeuronsForEachLayer(int n0, int n1, int n2){
	N0 = n0;
	N1 = n1;
	N2 = n2;
	std::vector<double> firstLayerActivations(N0, 0.0);
	std::vector<double> secondLayerActivations(N1, 0.0);
	std::vector<double> outputLayerActivations(N2, 0.0);
}
//---------------------------------------------------------------------------

//std::mt19937 g(static_cast<unsigned>(std::chrono::system_clock::now().time_since_epoch().count()));
void Network::GenerateWeights() {
	std::random_device rd;
	std::mt19937 gen(rd());
	std::uniform_real_distribution<> dis(-1.0, 1.0);

	std::vector<std::vector<double>> firstHiddenLayer;
	for (int i = 0; i < N0; ++i) {
		std::vector<double> neuron;
		for (int j = 0; j < 3; ++j) {
			neuron.push_back(dis(gen));
		}
		firstHiddenLayer.push_back(neuron);
	}
	std::vector<std::vector<double>> secondHiddenLayer;
	for (int i = 0; i < N1; ++i) {
		std::vector<double> neuron;
		for (int j = 0; j < N0+1; ++j) {
			neuron.push_back(dis(gen));
		}
		secondHiddenLayer.push_back(neuron);
	}

	std::vector<std::vector<double>> outputLayer;
	for (int i = 0; i < N2; ++i) {
		std::vector<double> neuron;
		for (int j = 0; j < N1+1; ++j) {
			neuron.push_back(dis(gen));
		}
		outputLayer.push_back(neuron);
	}
	network.push_back(firstHiddenLayer);
	network.push_back(secondHiddenLayer);
	network.push_back(outputLayer);
}
//---------------------------------------------------------------------------

std::vector<double> Network::Activate(int x0, int x1) {

	for (int i = 0; i < N0; ++i) {
		firstLayerActivations[i]+=network[0][i][0]*x0+network[0][i][1]*x1+
										network[0][i][2];
	}
	for (int i = 0; i < N0; ++i) {
		firstLayerActivations[i]=Sigmoid(firstLayerActivations[i]);
	}

	for (int i = 0; i < N1; ++i) {
		for (int j = 0; j < N1; ++j) {
			secondLayerActivations[i]+=network[1][i][j]*firstLayerActivations[j];
		}
		secondLayerActivations[i]+=network[1][i][N0];
	}
	for (int i = 0; i < N1; ++i) {
		secondLayerActivations[i]=Sigmoid(secondLayerActivations[i]);
	}

	for (int i = 0; i < N2; ++i) {
		for (int j = 0; j < N1; ++j) {
			outputLayerActivations[i]+=network[2][i][j]*secondLayerActivations[j];
		}
		outputLayerActivations[i]+=network[2][i][N1];
	}
	for (int i = 0; i < N2; ++i) {
		outputLayerActivations[i]=Sigmoid(outputLayerActivations[i]);
	}
	return outputLayerActivations;

}
//---------------------------------------------------------------------------

double Network::Sigmoid(double activation) const {
	return 1/(1+ std::exp(-activation));
}
//---------------------------------------------------------------------------

void Network::ForwardPropagate() {
	std::vector<double> outputLayer = Activate(0,0);
}
//---------------------------------------------------------------------------

void Network::BackwardPropagateError() {

}
//---------------------------------------------------------------------------
